<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Idefics Code Reading Notes | Qun Gu</title>
<meta name="keywords" content="">
<meta name="description" content="Background IDEFICS is a Multimodal Large Language Model (MLLM) or Vision-Language Model (VLM) published first on arXiv on June 21, 2023, and then on HuggingFace on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.
Fortunately, the model is an open source code on the transformers repo on GitHub, which leaves me with some clues to learn more.">
<meta name="author" content="Qun Gu">
<link rel="canonical" href="http://localhost:1313/posts/idefics-reading-notes/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/idefics-reading-notes/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body, 
    {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '\\[', right: '\\]', display: true},
                  {left: '$', right: '$', display: false},
                  {left: '\\(', right: '\\)', display: false}
              ]
          }
    );"></script>

  

<meta property="og:title" content="Idefics Code Reading Notes" />
<meta property="og:description" content="Background IDEFICS is a Multimodal Large Language Model (MLLM) or Vision-Language Model (VLM) published first on arXiv on June 21, 2023, and then on HuggingFace on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.
Fortunately, the model is an open source code on the transformers repo on GitHub, which leaves me with some clues to learn more." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/idefics-reading-notes/" />
<meta property="og:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-04-24T21:24:11-07:00" />
<meta property="article:modified_time" content="2024-04-24T21:24:11-07:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="http://localhost:1313/images/papermod-cover.png" />
<meta name="twitter:title" content="Idefics Code Reading Notes"/>
<meta name="twitter:description" content="Background IDEFICS is a Multimodal Large Language Model (MLLM) or Vision-Language Model (VLM) published first on arXiv on June 21, 2023, and then on HuggingFace on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.
Fortunately, the model is an open source code on the transformers repo on GitHub, which leaves me with some clues to learn more."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Idefics Code Reading Notes",
      "item": "http://localhost:1313/posts/idefics-reading-notes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Idefics Code Reading Notes",
  "name": "Idefics Code Reading Notes",
  "description": "Background IDEFICS is a Multimodal Large Language Model (MLLM) or Vision-Language Model (VLM) published first on arXiv on June 21, 2023, and then on HuggingFace on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.\nFortunately, the model is an open source code on the transformers repo on GitHub, which leaves me with some clues to learn more.",
  "keywords": [
    
  ],
  "articleBody": "Background IDEFICS is a Multimodal Large Language Model (MLLM) or Vision-Language Model (VLM) published first on arXiv on June 21, 2023, and then on HuggingFace on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.\nFortunately, the model is an open source code on the transformers repo on GitHub, which leaves me with some clues to learn more.\nStructure In the idefics folder, there are 7 files, including __init__.py. We have configuration_idefics.py, image_processing_idefics.py, modeling_idefics.py, perceiver.py, processing_idefics.py, and vision.py. Reading from name, seems that modeling_idefics.py is probably a good starting point.\nModeling Imports Opening modeling_idefics.py, we have a pretty large file that contains 1588 lines of code. I am learning some very basic things from this code.\nLearning Point 1 - dataclasses\nFirst, the first clause is\nfrom dataclasses import dataclass Here, dataclasses is a Python Standard Library which I didn’t use frequently before. It is a decorator which is conceptually wrapper (of a function). decorator can also be put in front of a class, which makes writing class much easier. On the documentation of dataclasses, there is a very good illustrative example. For the code below,\nfrom dataclasses import dataclass @dataclass class InventoryItem: \"\"\"Class for keeping track of an item in inventory.\"\"\" name: str unit_price: float quantity_on_hand: int = 0 def total_cost(self) -\u003e float: return self.unit_price * self.quantity_on_hand @dataclass will add an initial function __init__() that looks like this:\ndef __init__(self, name: str, unit_price: float, quantity_on_hand: int = 0): self.name = name self.unit_price = unit_price self.quantity_on_hand = quantity_on_hand Learning Point 2 - typing\nThe second clause:\nfrom typing import Any, Dict, List, Optional, Tuple, Union is also something I haven’t been using very often. It enables a more strict way of programming Python.\nThen, there are 5 lines of PyTorch imports, pretty commonly seen.\nLearning Point 3 - relative import\nAfter that, there are some relative imports from this package:\nfrom ... import PreTrainedModel from ...activations import ACT2FN from ...modeling_attn_mask_utils import _prepare_4d_causal_attention_mask_for_sdpa from ...modeling_outputs import ModelOutput from ...modeling_utils import PretrainedConfig from ...pytorch_utils import ALL_LAYERNORM_LAYERS from ...utils import ( add_start_docstrings, add_start_docstrings_to_model_forward, logging, replace_return_docstrings, ) from .configuration_idefics import IdeficsConfig from .perceiver import IdeficsPerceiverResampler from .vision import IdeficsVisionTransformer One dot is current directory (idefics). Two dots is parent directory (models). Three docs is grandparent directory (transformers).\nLearning Point 4 — A dictionary with function with arguments\nACT2FN is defined in the activations.py under transformers folder as\nACT2FN = ClassInstantier(ACT2CLS) where ACT2CLS is a dictionary,\nACT2CLS = { \"gelu\": GELUActivation, \"gelu_10\": (ClippedGELUActivation, {\"min\": -10, \"max\": 10}), \"gelu_fast\": FastGELUActivation, \"gelu_new\": NewGELUActivation, \"gelu_python\": (GELUActivation, {\"use_gelu_python\": True}), \"gelu_pytorch_tanh\": PytorchGELUTanh, \"gelu_accurate\": AccurateGELUActivation, \"laplace\": LaplaceActivation, \"leaky_relu\": nn.LeakyReLU, \"linear\": LinearActivation, \"mish\": MishActivation, \"quick_gelu\": QuickGELUActivation, \"relu\": nn.ReLU, \"relu2\": ReLUSquaredActivation, \"relu6\": nn.ReLU6, \"sigmoid\": nn.Sigmoid, \"silu\": nn.SiLU, \"swish\": nn.SiLU, \"tanh\": nn.Tanh, } whose keys are shorthands of activation functions classes (PyTorch Module), and values are the activation function class themselves. The ClassInstantier is defined just above\nclass ClassInstantier(OrderedDict): def __getitem__(self, key): content = super().__getitem__(key) cls, kwargs = content if isinstance(content, tuple) else (content, {}) return cls(**kwargs) which is a subclass that inherits OrderedDict, where __getitem__ is getting override. Effectively, when one call\nACT2FN[\"relu\"] one will get a nn.ReLU module.\nIn the modeling_attn_mask_utils there is a function _prepare_4d_causal_attention_mask_for_sdpa getting imported. Here, SDPA means Scaled Dot Product Attention, which is a critical layer in transformer models. The code is a bit daunting at first look, but I can at least get a sense what is going on at high level.\nThis function takes a attention mask, input shape, inputs embeddings, past key value length, sliding window as inputs. And outputs a expanded 4d mask. At first, an attention mask converter is getting created. The new key value length is the current input shape plus the past key value length. Then a boolean variable is_tracing is defined, which seems magical. Then, a ignore causal mask is getting created. If is not None, then return None. If attention mask is None, then it’s some how generated. Otherwise, attention mask is not None, and there are some other steps to generate the expanded 4d mask.\nI know the above paragraph is a bit hard to get because I haven’t fully got it. But there are some other questions in my mind.\nLearning Point 5 — What is Union?\nUnion is another name for “or” or “$\\cup$” that is used for construct a supertype, e.g. var: str | None accepts a variable that is either string or None.\nLearning Point 6 — torch\nWhat is torch.finfo? torch.finfo is similar to numpy.finfo, which gives the information of float type. There is a related routine called iinfo which gives the information for the integer type. By information, we mean, min, max, precision, etc.\nWhat is torch.jit.is_tracing? What is torch.fx.Proxy? What is torch._dynamo? These are all related with computational graph, compiler of torch, which is aiming at high performance computing.\nContinue reading, there are some other classes getting imported, e.g. ModelOutput, PretrainedConfig, ALL_LAYERNORM_LAYERS, 3 routines related to docstrings, and 1 with logging.\nThere are 3 more classes coming from the current package: IdeficsConfig, IdeficsPerceiverResampler, and IdeficsVisionTransformer. There is one more constant that is getting imported, that is IDEFICS_PRETRAINED_MODEL_ARCHIVE_LIST.\nLogging is set to logger global variable, and _CONFIG_FOR_DOC is a string called \"IdeficsConfig\".\nIdeficsBaseModelOutputWithPast This is the first class of this file. It contains a past key/values to speed up sequential decoding. It is a subclass of ModelOutput, where there are 5 additional variables:\nlast_hidden_state — float tensor past_key_values — ((float tensor, float tensor), (float tensor, float tensor), …) hidden_states — (float tensor, float tensor, …) attentions — (float tensor, float tensor, …) image_hidden_states — (float tensor, float tensor, …) IdeficsCausalLMOutputWithPast Very similar to the previous one, but with 6 additional variables:\nloss logits past_key_values hidden_states attentions image_hidden_states So no last_hidden_state, but with 2 additional variables: loss and logits.\nexpand_inputs_for_generation Remaining Questions About AttentionMaskConverter\nWhat does _ignore_causal_mask_sdpa do? What does to_causal_4d do? What does to_4d do? What does _unmask_unattended do? Further reading Illustrated Transformer by Jay Alammar Tensorflow Tutorial on Transformer ",
  "wordCount" : "1004",
  "inLanguage": "en",
  "image": "http://localhost:1313/images/papermod-cover.png","datePublished": "2024-04-24T21:24:11-07:00",
  "dateModified": "2024-04-24T21:24:11-07:00",
  "author":{
    "@type": "Person",
    "name": "Qun Gu"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/idefics-reading-notes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Qun Gu",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Qun Gu (Alt + H)">Qun Gu</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://localhost:1313/">Home</a>&nbsp;»&nbsp;<a href="http://localhost:1313/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Idefics Code Reading Notes
    </h1>
    <div class="post-meta"><span title='2024-04-24 21:24:11 -0700 PDT'>April 24, 2024</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Qun Gu&nbsp;|&nbsp;<a href="https://github.com/vcdim/vcdim.github.io/tree/main/content/posts/idefics-reading-notes.md" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#background" aria-label="Background">Background</a></li>
                <li>
                    <a href="#structure" aria-label="Structure">Structure</a><ul>
                        
                <li>
                    <a href="#modeling" aria-label="Modeling">Modeling</a><ul>
                        
                <li>
                    <a href="#imports" aria-label="Imports">Imports</a></li>
                <li>
                    <a href="#ideficsbasemodeloutputwithpast" aria-label="IdeficsBaseModelOutputWithPast">IdeficsBaseModelOutputWithPast</a></li>
                <li>
                    <a href="#ideficscausallmoutputwithpast" aria-label="IdeficsCausalLMOutputWithPast">IdeficsCausalLMOutputWithPast</a></li>
                <li>
                    <a href="#expand_inputs_for_generation" aria-label="expand_inputs_for_generation">expand_inputs_for_generation</a></li></ul>
                </li></ul>
                </li>
                <li>
                    <a href="#remaining-questions" aria-label="Remaining Questions">Remaining Questions</a></li>
                <li>
                    <a href="#further-reading" aria-label="Further reading">Further reading</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h2>
<p>IDEFICS is a <strong>M</strong>ultimodal <strong>L</strong>arge <strong>L</strong>anguage <strong>M</strong>odel (MLLM) or <strong>V</strong>ision-<strong>L</strong>anguage <strong>M</strong>odel (VLM) published first on <a href="https://arxiv.org/abs/2306.16527">arXiv</a> on June 21, 2023, and then on <a href="https://huggingface.co/blog/idefics">HuggingFace</a> on August 22, 2023. I had a chance to use this model to do some experiment but I have never had investigate the package in depth.</p>
<p>Fortunately, the model is an open source code on the <code>transformers</code> repo on <a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/idefics">GitHub</a>, which leaves me with some clues to learn more.</p>
<h2 id="structure">Structure<a hidden class="anchor" aria-hidden="true" href="#structure">#</a></h2>
<p>In the <code>idefics</code> folder, there are 7 files, including <code>__init__.py</code>. We have <code>configuration_idefics.py</code>, <code>image_processing_idefics.py</code>, <code>modeling_idefics.py</code>, <code>perceiver.py</code>, <code>processing_idefics.py</code>, and <code>vision.py</code>. Reading from name, seems that <code>modeling_idefics.py</code> is probably a good starting point.</p>
<h3 id="modeling">Modeling<a hidden class="anchor" aria-hidden="true" href="#modeling">#</a></h3>
<h4 id="imports">Imports<a hidden class="anchor" aria-hidden="true" href="#imports">#</a></h4>
<p>Opening <code>modeling_idefics.py</code>, we have a pretty large file that contains 1588 lines of code. I am learning some very basic things from this code.</p>
<blockquote>
<p><strong>Learning Point 1</strong> - <code>dataclasses</code></p>
</blockquote>
<p>First, the first clause is</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
</span></span></code></pre></div><p>Here, <code>dataclasses</code> is a Python Standard Library which I didn&rsquo;t use frequently before. It is a <code>decorator</code> which is conceptually wrapper (of a function). <code>decorator</code> can also be put in front of a class, which makes writing class much easier. On the <a href="https://docs.python.org/3/library/dataclasses.html">documentation</a> of <code>dataclasses</code>, there is a very good illustrative example. For the code below,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">InventoryItem</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Class for keeping track of an item in inventory.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span>
</span></span><span class="line"><span class="cl">    <span class="n">unit_price</span><span class="p">:</span> <span class="nb">float</span>
</span></span><span class="line"><span class="cl">    <span class="n">quantity_on_hand</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">total_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unit_price</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantity_on_hand</span>
</span></span></code></pre></div><p><code>@dataclass</code> will add an initial function <code>__init__()</code> that looks like this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">unit_price</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">quantity_on_hand</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">unit_price</span> <span class="o">=</span> <span class="n">unit_price</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">quantity_on_hand</span> <span class="o">=</span> <span class="n">quantity_on_hand</span>
</span></span></code></pre></div><blockquote>
<p><strong>Learning Point 2</strong> - <code>typing</code></p>
</blockquote>
<p>The second clause:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
</span></span></code></pre></div><p>is also something I haven&rsquo;t been using very often. It enables a more strict way of programming Python.</p>
<p>Then, there are 5 lines of PyTorch imports, pretty commonly seen.</p>
<blockquote>
<p><strong>Learning Point 3</strong> - relative import</p>
</blockquote>
<p>After that, there are some relative imports from this package:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...</span> <span class="kn">import</span> <span class="n">PreTrainedModel</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...activations</span> <span class="kn">import</span> <span class="n">ACT2FN</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...modeling_attn_mask_utils</span> <span class="kn">import</span> <span class="n">_prepare_4d_causal_attention_mask_for_sdpa</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...modeling_outputs</span> <span class="kn">import</span> <span class="n">ModelOutput</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...modeling_utils</span> <span class="kn">import</span> <span class="n">PretrainedConfig</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...pytorch_utils</span> <span class="kn">import</span> <span class="n">ALL_LAYERNORM_LAYERS</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">...utils</span> <span class="kn">import</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_start_docstrings</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">add_start_docstrings_to_model_forward</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">logging</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">replace_return_docstrings</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">.configuration_idefics</span> <span class="kn">import</span> <span class="n">IdeficsConfig</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">.perceiver</span> <span class="kn">import</span> <span class="n">IdeficsPerceiverResampler</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">.vision</span> <span class="kn">import</span> <span class="n">IdeficsVisionTransformer</span>
</span></span></code></pre></div><p>One dot is current directory (<code>idefics</code>). Two dots is parent directory (<code>models</code>). Three docs is grandparent directory (<code>transformers</code>).</p>
<blockquote>
<p><strong>Learning Point 4</strong> &mdash; A dictionary with function with arguments</p>
</blockquote>
<p><code>ACT2FN</code> is defined in the <code>activations.py</code> under <code>transformers</code> folder as</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ACT2FN</span> <span class="o">=</span> <span class="n">ClassInstantier</span><span class="p">(</span><span class="n">ACT2CLS</span><span class="p">)</span>
</span></span></code></pre></div><p>where <code>ACT2CLS</code> is a dictionary,</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ACT2CLS</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu&#34;</span><span class="p">:</span> <span class="n">GELUActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_10&#34;</span><span class="p">:</span> <span class="p">(</span><span class="n">ClippedGELUActivation</span><span class="p">,</span> <span class="p">{</span><span class="s2">&#34;min&#34;</span><span class="p">:</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="s2">&#34;max&#34;</span><span class="p">:</span> <span class="mi">10</span><span class="p">}),</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_fast&#34;</span><span class="p">:</span> <span class="n">FastGELUActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_new&#34;</span><span class="p">:</span> <span class="n">NewGELUActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_python&#34;</span><span class="p">:</span> <span class="p">(</span><span class="n">GELUActivation</span><span class="p">,</span> <span class="p">{</span><span class="s2">&#34;use_gelu_python&#34;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}),</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_pytorch_tanh&#34;</span><span class="p">:</span> <span class="n">PytorchGELUTanh</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;gelu_accurate&#34;</span><span class="p">:</span> <span class="n">AccurateGELUActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;laplace&#34;</span><span class="p">:</span> <span class="n">LaplaceActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;leaky_relu&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;linear&#34;</span><span class="p">:</span> <span class="n">LinearActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;mish&#34;</span><span class="p">:</span> <span class="n">MishActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;quick_gelu&#34;</span><span class="p">:</span> <span class="n">QuickGELUActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;relu&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;relu2&#34;</span><span class="p">:</span> <span class="n">ReLUSquaredActivation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;relu6&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;sigmoid&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;silu&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;swish&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;tanh&#34;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>whose keys are shorthands of activation functions classes (PyTorch Module), and values are the activation function class themselves. The <code>ClassInstantier</code> is defined just above</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ClassInstantier</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">content</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">cls</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">content</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="p">{})</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span></code></pre></div><p>which is a subclass that inherits <code>OrderedDict</code>, where <code>__getitem__</code> is getting override. Effectively, when one call</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">ACT2FN</span><span class="p">[</span><span class="s2">&#34;relu&#34;</span><span class="p">]</span>
</span></span></code></pre></div><p>one will get a <code>nn.ReLU</code> module.</p>
<p>In the <code>modeling_attn_mask_utils</code> there is a function <code>_prepare_4d_causal_attention_mask_for_sdpa</code> getting imported. Here, SDPA means <strong>S</strong>caled <strong>D</strong>ot <strong>P</strong>roduct <strong>A</strong>ttention, which is a critical layer in transformer models. The code is a bit daunting at first look, but I can at least get a sense what is going on at high level.</p>
<p>This function takes a attention mask, input shape, inputs embeddings, past key value length, sliding window as inputs. And outputs a expanded 4d mask. At first, an attention mask converter is getting created. The new key value length is the current input shape plus the past key value length. Then a boolean variable <code>is_tracing</code> is defined, which seems magical. Then, a ignore causal mask is getting created. If is not None, then return None. If attention mask is None, then it&rsquo;s some how generated. Otherwise, attention mask is not None, and there are some other steps to generate the expanded 4d mask.</p>
<p>I know the above paragraph is a bit hard to get because I haven&rsquo;t fully got it. But there are some other questions in my mind.</p>
<blockquote>
<p><strong>Learning Point 5</strong> &mdash; What is <code>Union</code>?</p>
</blockquote>
<p>Union is another name for &ldquo;or&rdquo; or &ldquo;$\cup$&rdquo; that is used for construct a supertype, e.g. <code>var: str | None</code> accepts a variable that is either string or <code>None</code>.</p>
<blockquote>
<p><strong>Learning Point 6</strong> &mdash; <code>torch</code></p>
</blockquote>
<p><strong>What is <code>torch.finfo</code>?</strong> <code>torch.finfo</code> is similar to <code>numpy.finfo</code>, which gives the information of float type. There is a related routine called <code>iinfo</code> which gives the information for the integer type. By information, we mean, min, max, precision, etc.</p>
<p><strong>What is <code>torch.jit.is_tracing</code>? What is <code>torch.fx.Proxy</code>? What is <code>torch._dynamo</code>?</strong> These are all related with computational graph, compiler of torch, which is aiming at high performance computing.</p>
<p>Continue reading, there are some other classes getting imported, e.g. <code>ModelOutput</code>, <code>PretrainedConfig</code>, <code>ALL_LAYERNORM_LAYERS</code>, 3 routines related to docstrings, and 1 with logging.</p>
<p>There are 3 more classes coming from the current package: <code>IdeficsConfig</code>, <code>IdeficsPerceiverResampler</code>, and <code>IdeficsVisionTransformer</code>. There is one more constant that is getting imported, that is <code>IDEFICS_PRETRAINED_MODEL_ARCHIVE_LIST</code>.</p>
<p>Logging is set to <code>logger</code> global variable, and <code>_CONFIG_FOR_DOC</code> is a string called <code>&quot;IdeficsConfig&quot;</code>.</p>
<h4 id="ideficsbasemodeloutputwithpast"><code>IdeficsBaseModelOutputWithPast</code><a hidden class="anchor" aria-hidden="true" href="#ideficsbasemodeloutputwithpast">#</a></h4>
<p>This is the first class of this file. It contains a past key/values to speed up sequential decoding. It is a subclass of <code>ModelOutput</code>, where there are 5 additional variables:</p>
<ul>
<li><code>last_hidden_state</code> &mdash; float tensor</li>
<li><code>past_key_values</code> &mdash; ((float tensor, float tensor), (float tensor, float tensor), &hellip;)</li>
<li><code>hidden_states</code> &mdash; (float tensor, float tensor, &hellip;)</li>
<li><code>attentions</code> &mdash; (float tensor, float tensor, &hellip;)</li>
<li><code>image_hidden_states</code>  &mdash; (float tensor, float tensor, &hellip;)</li>
</ul>
<h4 id="ideficscausallmoutputwithpast"><code>IdeficsCausalLMOutputWithPast</code><a hidden class="anchor" aria-hidden="true" href="#ideficscausallmoutputwithpast">#</a></h4>
<p>Very similar to the previous one, but with 6 additional variables:</p>
<ul>
<li><code>loss</code></li>
<li><code>logits</code></li>
<li><code>past_key_values</code></li>
<li><code>hidden_states</code></li>
<li><code>attentions</code></li>
<li><code>image_hidden_states</code></li>
</ul>
<p>So no <code>last_hidden_state</code>, but with 2 additional variables: <code>loss</code> and <code>logits</code>.</p>
<h4 id="expand_inputs_for_generation"><code>expand_inputs_for_generation</code><a hidden class="anchor" aria-hidden="true" href="#expand_inputs_for_generation">#</a></h4>
<h2 id="remaining-questions">Remaining Questions<a hidden class="anchor" aria-hidden="true" href="#remaining-questions">#</a></h2>
<p>About <code>AttentionMaskConverter</code></p>
<ul>
<li>What does <code>_ignore_causal_mask_sdpa</code> do?</li>
<li>What does <code>to_causal_4d</code> do?</li>
<li>What does <code>to_4d</code> do?</li>
<li>What does <code>_unmask_unattended</code> do?</li>
</ul>
<h2 id="further-reading">Further reading<a hidden class="anchor" aria-hidden="true" href="#further-reading">#</a></h2>
<ul>
<li><a href="https://jalammar.github.io/illustrated-transformer/">Illustrated Transformer by Jay Alammar</a></li>
<li><a href="https://www.tensorflow.org/text/tutorials/transformer">Tensorflow Tutorial on Transformer</a></li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="next" href="http://localhost:1313/posts/hello/">
    <span class="title">Next »</span>
    <br>
    <span>My First Post</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on x"
            href="https://x.com/intent/tweet/?text=Idefics%20Code%20Reading%20Notes&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f&amp;title=Idefics%20Code%20Reading%20Notes&amp;summary=Idefics%20Code%20Reading%20Notes&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f&title=Idefics%20Code%20Reading%20Notes">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on whatsapp"
            href="https://api.whatsapp.com/send?text=Idefics%20Code%20Reading%20Notes%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on telegram"
            href="https://telegram.me/share/url?text=Idefics%20Code%20Reading%20Notes&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Idefics Code Reading Notes on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Idefics%20Code%20Reading%20Notes&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fidefics-reading-notes%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2024 <a href="http://localhost:1313/">Qun Gu</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
